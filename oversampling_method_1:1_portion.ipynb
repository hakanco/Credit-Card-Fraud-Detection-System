{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a Balanced Oversampling Technique with a 1:1 Target Label Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import regexp_replace, col, when, substring, concat, lit, to_date, date_format\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, VectorIndexer\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start a simple Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/11 21:29:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('fraud_detection').master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/11 21:29:49 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "col_names = ['User', 'Card', 'Year', 'Month', 'Day', 'Time', 'Amount', 'Use Chip', 'Merchant Name', 'Merchant City', \n",
    "'Merchant State', 'MCC', 'Errors?', 'Is Fraud?', 'Hour', 'Minute', 'Date', 'Day_of_Week']\n",
    "\n",
    "df = spark.read.option(\"delimiter\", \"|\").csv('credit_card_transactions.csv', header=None, inferSchema=True).toDF(*col_names)\n",
    "df = df.repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User: integer (nullable = true)\n",
      " |-- Card: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- Day: integer (nullable = true)\n",
      " |-- Time: timestamp (nullable = true)\n",
      " |-- Amount: double (nullable = true)\n",
      " |-- Use Chip: string (nullable = true)\n",
      " |-- Merchant Name: long (nullable = true)\n",
      " |-- Merchant City: string (nullable = true)\n",
      " |-- Merchant State: string (nullable = true)\n",
      " |-- MCC: integer (nullable = true)\n",
      " |-- Errors?: string (nullable = true)\n",
      " |-- Is Fraud?: integer (nullable = true)\n",
      " |-- Hour: double (nullable = true)\n",
      " |-- Minute: double (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Day_of_Week: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding Some Categorical Fields for Spark Pipeline & Create Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = []\n",
    "categorical_cols = ['Use Chip', 'Day_of_Week']\n",
    "numerical_cols = ['Card', 'Year', 'Month', 'Day', 'Amount', 'MCC', 'Hour', 'Minute']\n",
    "\n",
    "# Indexers for categorical columns\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col+'_indexed') for col in categorical_cols]\n",
    "# Encoders for categorical columns\n",
    "encoders = [OneHotEncoder(inputCol=col+'_indexed', outputCol=col+'_OHE') for col in categorical_cols]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=(numerical_cols + ['Use Chip_OHE', 'Day_of_Week_OHE']),\n",
    "                            outputCol='features')\n",
    "\n",
    "lr_model = LogisticRegression(featuresCol='features', labelCol='Is Fraud?')\n",
    "\n",
    "stages = indexers + encoders + [assembler, lr_model]\n",
    "\n",
    "pipeline = Pipeline(stages=stages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Oversampling Minority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_minority(df):\n",
    "    \n",
    "    num_limit = 300000\n",
    "\n",
    "    fraction = num_limit / df.filter(col('Is Fraud?') == 0).count()\n",
    "\n",
    "    df_normal = df.filter(col('Is Fraud?')==0).sample(withReplacement=False, fraction=fraction, seed=42)\n",
    "    \n",
    "    fraud_count = df.filter(col('Is Fraud?')==1).count()\n",
    "\n",
    "    balance_ratio = num_limit / fraud_count\n",
    "    \n",
    "    oversampled_minority = df.filter(col('Is Fraud?')==1).sample(withReplacement=True, fraction=(balance_ratio), seed=42)\n",
    "    oversampled_df = df_normal.union(oversampled_minority)\n",
    "    \n",
    "    return oversampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "oversample_balanced_df = oversample_minority(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=====================================================>  (25 + 1) / 26]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|Is Fraud?| count|\n",
      "+---------+------+\n",
      "|        0|300444|\n",
      "|        1|299918|\n",
      "+---------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "oversample_balanced_df.groupBy('Is Fraud?').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_oversampled, test_oversampled = oversample_balanced_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/11 21:33:16 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/06/11 21:33:16 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "[Stage 120:====================================================>  (25 + 1) / 26]\r"
     ]
    }
   ],
   "source": [
    "lr_oversampled_model = pipeline.fit(train_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_oversampled_model.transform(test_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7624068112917932"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='Is Fraud?')\n",
    "AUC = my_eval.evaluate(predictions)\n",
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 182:=================================>                     (12 + 8) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7622171039455238\n",
      "F1 Score: 0.759422484500134\n",
      "Precision label 1: 0.8354007532075151\n",
      "Recall label 1: 0.6541543793005782\n",
      "Precision label 0: 0.7149918306262272\n",
      "Recall label 0: 0.8706592432830081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Is Fraud?\", predictionCol=\"prediction\")\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"Is Fraud?\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "precision_label_0 = evaluator_precision.evaluate(predictions, {evaluator_precision.metricLabel: 0.0})\n",
    "precision_label_1 = evaluator_precision.evaluate(predictions, {evaluator_precision.metricLabel: 1.0})\n",
    "\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"Is Fraud?\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "recall_label_0 = evaluator_recall.evaluate(predictions, {evaluator_recall.metricLabel: 0.0})\n",
    "recall_label_1 = evaluator_recall.evaluate(predictions, {evaluator_recall.metricLabel: 1.0})\n",
    "\n",
    "\n",
    "f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "# Print the metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "print(f\"Precision label 1: {precision_label_1}\")\n",
    "print(f\"Recall label 1: {recall_label_1}\")\n",
    "\n",
    "print(f\"Precision label 0: {precision_label_0}\")\n",
    "print(f\"Recall label 0: {recall_label_0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 206:============================================>          (16 + 4) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----+\n",
      "|Is Fraud?|  0.0|  1.0|\n",
      "+---------+-----+-----+\n",
      "|        0|52075| 7736|\n",
      "|        1|20758|39263|\n",
      "+---------+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix manually\n",
    "confusion_matrix = predictions.groupBy(\"Is Fraud?\").pivot(\"prediction\").count().na.fill(0).orderBy(\"Is Fraud?\")\n",
    "confusion_matrix.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

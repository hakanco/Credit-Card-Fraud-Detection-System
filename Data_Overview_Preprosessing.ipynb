{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_replace, col, when, substring, concat, lit, to_date, date_format, sum as _sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start a simple Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/11 21:17:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/06/11 21:17:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('fraud_detection_data_overview').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('credit_card_transactions-ibm_v2.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User: integer (nullable = true)\n",
      " |-- Card: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- Day: integer (nullable = true)\n",
      " |-- Time: timestamp (nullable = true)\n",
      " |-- Amount: string (nullable = true)\n",
      " |-- Use Chip: string (nullable = true)\n",
      " |-- Merchant Name: long (nullable = true)\n",
      " |-- Merchant City: string (nullable = true)\n",
      " |-- Merchant State: string (nullable = true)\n",
      " |-- Zip: double (nullable = true)\n",
      " |-- MCC: integer (nullable = true)\n",
      " |-- Errors?: string (nullable = true)\n",
      " |-- Is Fraud?: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/11 21:17:23 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/06/11 21:17:25 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "[Stage 2:=====================================================>   (17 + 1) / 18]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+------------------+------------------+--------+-----------------+--------------------+-------------+--------------+------------------+-----------------+----------------+---------+\n",
      "|summary|              User|              Card|              Year|             Month|               Day|  Amount|         Use Chip|       Merchant Name|Merchant City|Merchant State|               Zip|              MCC|         Errors?|Is Fraud?|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+--------+-----------------+--------------------+-------------+--------------+------------------+-----------------+----------------+---------+\n",
      "|  count|          24386900|          24386900|          24386900|          24386900|          24386900|24386900|         24386900|            24386900|     24386900|      21666079|          21508765|         24386900|          388431| 24386900|\n",
      "|   mean|1001.0193350938414| 1.351366184303868|2011.9551699067943|  6.52506357921671|15.718122721625134|    NULL|             NULL|-4.76922962773083...|         NULL|          NULL| 50956.44211506332|5561.171253336833|            NULL|     NULL|\n",
      "| stddev|  569.461157032364|1.4071536259341337| 5.105920688923689|3.4723548345729336| 8.794073288462647|    NULL|             NULL| 4.75893987068398E18|         NULL|          NULL|29397.065949063544|879.3154327182826|            NULL|     NULL|\n",
      "|    min|                 0|                 0|              1991|                 1|                 1|  $-0.00| Chip Transaction|-9222899435637403521|   Aaronsburg|            AA|             501.0|             1711|         Bad CVV|       No|\n",
      "|    max|              1999|                 8|              2020|                12|                31| $999.97|Swipe Transaction| 9223291803303717674|       Zwolle|      Zimbabwe|           99928.0|             9402|Technical Glitch|      Yes|\n",
      "+-------+------------------+------------------+------------------+------------------+------------------+--------+-----------------+--------------------+-------------+--------------+------------------+-----------------+----------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Field Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=====================================================>   (17 + 1) / 18]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|Is Fraud?|   count|\n",
      "+---------+--------+\n",
      "|      Yes|   29757|\n",
      "|       No|24357143|\n",
      "+---------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupBy('Is Fraud?').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fraud = df[df['Is Fraud?']=='Yes']\n",
    "\n",
    "Normal = df[df['Is Fraud?']=='No']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.12202042900081601"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_dist = Fraud.count()/float(df.count())\n",
    "fraud_dist*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of fraud cases reveals a highly imbalanced dataset, with the target class (fraud, Class==1) constituting only 0.122% of the total dataset. This raises a significant concern because most machine learning models are optimized to maximize accuracy. Consequently, classifying all transactions as normal would yield a substantial accuracy score, which is not beneficial for effective detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"User\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2000 customers involved in these transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:====================================================>   (17 + 1) / 18]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----+---+----+------+--------+-------------+-------------+--------------+-------+---+--------+---------+\n",
      "|User|Card|Year|Month|Day|Time|Amount|Use Chip|Merchant Name|Merchant City|Merchant State|    Zip|MCC| Errors?|Is Fraud?|\n",
      "+----+----+----+-----+---+----+------+--------+-------------+-------------+--------------+-------+---+--------+---------+\n",
      "|   0|   0|   0|    0|  0|   0|     0|       0|            0|            0|       2720821|2878135|  0|23998469|        0|\n",
      "+----+----+----+-----+---+----+------+--------+-------------+-------------+--------------+-------+---+--------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count null values for each column\n",
    "null_counts = df.select([_sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])\n",
    "\n",
    "# Show the counts of null values\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:====================================================>   (17 + 1) / 18]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "|Is Fraud?|  count|\n",
      "+---------+-------+\n",
      "|       No|2853283|\n",
      "|      Yes|  24852|\n",
      "+---------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "null_zip_df = df.filter(col('Zip').isNull())\n",
    "\n",
    "# Group by 'Label' column and count occurrences\n",
    "fraud_counts = null_zip_df.groupBy('Is Fraud?').count()\n",
    "\n",
    "# Show the results\n",
    "fraud_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the analysis indicate a significant disparity in the occurrence of null values in the 'Zip' column between fraudulent and non-fraudulent transactions. \n",
    "Specifically, the data shows:<br><br>\n",
    "24,852 fraudulent transactions (Label = 1) with null values in the 'Zip' column.<br>\n",
    "2,853,283 non-fraudulent transactions (Label = 0) with null values in the 'Zip' column.<br><br>\n",
    "This implies that a substantial percentage of the total null 'Zip' values are associated with fraudulent transactions. <br>\n",
    "This pattern suggests a correlation between missing 'Zip' data and fraudulent activity, so needs a further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    # df['Amount'] = df['Amount'].str.replace('$', \"\").astype(float)\n",
    "    df = df.withColumn('Amount', regexp_replace(col('Amount'), '\\\\$', '').cast('float'))\n",
    "\n",
    "    # df['Is Fraud?'] = df['Is Fraud?'].apply(lambda x: 0 if x=='No' else 1)\n",
    "    df = df.withColumn('Is Fraud?', when(col('Is Fraud?') == \"No\", 0).otherwise(1))\n",
    "\n",
    "    df = df.withColumn('Hour', substring('Time', 12, 2))\n",
    "    df = df.withColumn('Minute', substring('Time', 15, 2))\n",
    "\n",
    "    df = df.withColumn('Date', to_date(concat(col('Year'), lit('-'), col('Month'), lit('-'), col('Day')), 'yyyy-M-d'))\n",
    "\n",
    "    df = df.withColumn('Day_of_Week', date_format('Date', 'EEEE'))\n",
    "\n",
    "    # convert 'Hour' and 'Minute' fields into float data type\n",
    "    df = df.withColumn('Hour', col('Hour').cast('float'))\n",
    "    df = df.withColumn('Minute', col('Minute').cast('float'))\n",
    "    df = df.drop('Zip')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----+---+-------------------+------+-----------------+-------------------+-------------+--------------+----+-------+---------+----+------+----------+-----------+\n",
      "|User|Card|Year|Month|Day|               Time|Amount|         Use Chip|      Merchant Name|Merchant City|Merchant State| MCC|Errors?|Is Fraud?|Hour|Minute|      Date|Day_of_Week|\n",
      "+----+----+----+-----+---+-------------------+------+-----------------+-------------------+-------------+--------------+----+-------+---------+----+------+----------+-----------+\n",
      "|   0|   0|2002|    9|  1|2024-06-11 06:21:00|134.09|Swipe Transaction|3527213246127876953|     La Verne|            CA|5300|   NULL|        0| 6.0|  21.0|2002-09-01|     Sunday|\n",
      "|   0|   0|2002|    9|  1|2024-06-11 06:42:00| 38.48|Swipe Transaction|-727612092139916043|Monterey Park|            CA|5411|   NULL|        0| 6.0|  42.0|2002-09-01|     Sunday|\n",
      "+----+----+----+-----+---+-------------------+------+-----------------+-------------------+-------------+--------------+----+-------+---------+----+------+----------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = preprocess(df)\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.repartition(1).write.csv(\"df_EDA.csv\", sep='|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
